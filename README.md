# Generative Pre-trained Transformer AI Language Model
My own large language model
This is just the very start of a agetic ai llm that I've been thinking about. Has a few external dependancies, the main one being the OpenNMT Tokenizer from MIT (https://github.com/OpenNMT/Tokenizer), for now.

Todo: build NMT as a shared lib and register it with the linux system librarian.
